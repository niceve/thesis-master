[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "OpenRFSense - Explorative data analysis using software-defined radios",
    "section": "",
    "text": "Abstract\nPlaceholder for the abstract."
  },
  {
    "objectID": "chapters/introduction.html#background",
    "href": "chapters/introduction.html#background",
    "title": "1  Introduction",
    "section": "1.1 Background",
    "text": "1.1 Background\nTruly understanding customers is key to a successful business. Companies increasingly leverage data analytics to uncover insights into their customers’ needs, preferences, and socio-demographic profiles. This information is essential for enhancing user experiences, differentiating from competitors, and creating products that satisfy market demands. Moreover, understanding customers improves strategic planning by facilitating informed decisions about market positioning, pricing, and promotional strategies. By aligning marketing strategies with consumer needs, businesses can achieve more successful and impactful outcomes.\nTraditional approaches to understanding customers, such as surveys, focus groups, and market research reports, have long been relied upon. While these methods can provide useful insights, they have significant limitations. Surveys, for instance, often suffer from low response rates and biased results. Focus groups may not accurately represent the entire customer base, leading to incomplete or skewed findings. Market research reports, while detailed, are frequently expensive and time-consuming to produce. Additionally, these traditional methods typically provide only a static view of customer preferences, failing to capture the dynamic changes in consumer behavior over time.\nTo address these limitations, businesses are increasingly turning to more innovative approaches. One such approach is the analysis of customer-generated content, such as product reviews. Product reviews offer valuable insights into customer preferences and sentiments. Various techniques, including sentiment analysis, topic modeling, and natural language processing, can be employed to extract meaningful information from this user-generated content."
  },
  {
    "objectID": "chapters/introduction.html#research-objectives",
    "href": "chapters/introduction.html#research-objectives",
    "title": "1  Introduction",
    "section": "1.2 Research Objectives",
    "text": "1.2 Research Objectives\nTraditionally, product reviews have been analyzed primarily on feedback about the product, such as customer opinions, satisfaction levels, and sentiments on specific features. However, insights into customers’ personal attributes, behaviors, and usage contexts have not been thoroughly explored. Addressing this gap presents a valuable opportunity to leverage user-generated content for a deeper understanding of customers.\nThe extraction of personal attributes from product reviews is the focus of this research. Personal attributes are specific characteristics that uniquely describe an individual’s traits, lifestyle, and circumstances, such as physical appearance, profession, household composition, and living situation. These attributes could include details such as hair type, skin condition, profession, number of family members or pets, and whether they live in an apartment, townhouse or single-family home. By extracting personal attributes from product reviews, we aim to gain a deeper understanding of the characteristics of customers."
  },
  {
    "objectID": "chapters/introduction.html#related-work",
    "href": "chapters/introduction.html#related-work",
    "title": "1  Introduction",
    "section": "1.3 Related work",
    "text": "1.3 Related work\nRecent research has explored methods for extracting personal attributes from unstructured text. A significant portion of this work has been specifically focused on dialogues. Wang et al. (2022) explored the use of a language model to extract and infer personal attributes from human-human dialogue. DeLucia et al. (2024) presented a method for adapting persona extraction models to diverse conversational settings, enhancing the quality of persona information extracted from dialogues and reducing the need for extensive human annotation. Wu et al. (2024) introduced In-Dialogue Learning, a framework that enhances pre-trained language models to utilize dialogue history for persona extraction in personalized dialogue generation\nAll aforementioned studies employ triplet format. This means the format (s, r, o), where the relation (r) indicates the persona attribute type of the subject (s) towards the object (o). The benefits of triplet format are 1, 2, and 3.\nDespite their promising results, these studies have limitations. They rely on predefined lists of attributes, which constrain their ability to capture a broad range of relevant information and limit flexibility. In addition, models need to be fine-tuned to address these constraints, especially when applied to product reviews. There is a need for data to finetune."
  },
  {
    "objectID": "chapters/introduction.html#approach",
    "href": "chapters/introduction.html#approach",
    "title": "1  Introduction",
    "section": "1.4 Approach",
    "text": "1.4 Approach\nIn line with previous research on extracting personal attributes, this study will also use the triplet format to store these attributes. However, our approach diverges by addressing some of the key limitations of earlier studies, including that previous research often relied on predefined lists of attributes. Inspired by recent advancements in pre-trained large language models (LLMs), this work introduces a novel approach for extracting personal attributes using these models. Our method aims to extract triplets from product reviews without being limited by predefined attribute categories, thus offering a more comprehensive and adaptable solution to capture the various personal attributes revealed in customer feedback.\nWe present an end-to-end pipeline, starting from raw text all the way through to a constructed knowledge graph. The approach , text pre-processing, triplet extraction post-processing."
  },
  {
    "objectID": "chapters/introduction.html#main-contributions",
    "href": "chapters/introduction.html#main-contributions",
    "title": "1  Introduction",
    "section": "1.5 Main Contributions",
    "text": "1.5 Main Contributions\nThe main contributions of this thesis are as follows: * Pipeline: We developed an end-to-end pipeline that leverages large language models (LLMs) to automate the construction of Knowledge Graphs from unstructured data. * Comparison: We provided a comparison between our LLM-based approach and traditional triplet extraction methods. * Case Study Implementation: We conducted a detailed case study to evaluate the performance of our framework. * Future Direction: We identified potential areas for future research and development, offering insights into how the end-to-end pipeline can be further improved and extended."
  },
  {
    "objectID": "chapters/introduction.html#thesis-outline",
    "href": "chapters/introduction.html#thesis-outline",
    "title": "1  Introduction",
    "section": "1.6 Thesis Outline",
    "text": "1.6 Thesis Outline\nPlaceholder for thesis outline"
  },
  {
    "objectID": "chapters/system-architecture.html#high-level-components",
    "href": "chapters/system-architecture.html#high-level-components",
    "title": "2  System architecture",
    "section": "2.1 High-level components",
    "text": "2.1 High-level components\nOpenRFSense is built upon several different modern technologies, interconnected by mainstream networking protocols.\n\n2.1.1 Hardware\nOpenRFSense is designed to run on a variety of hardware platforms, including PCs, servers, and embedded systems. The hardware requirements depend on the specific use case and workload, but typically include a multi-core processor, sufficient memory and storage, and one or more software-defined radio (SDR) devices acting as signal receivers.\n\n\n2.1.2 Software-defined radio\nOpenRFSense relies on one or more SDR devices to capture and analyze radio frequency signals. The SDR devices are connected to the hardware platform via USB or PCIe interfaces and can be controlled using open-source software libraries such as GNU Radio. The SDR device is responsible for capturing radio signals from the environment.\n\n\n2.1.3 Operating system\nThanks to the choice of programming language (Golang (“The Go Programming Language,” n.d.)), both the backend and node software can be compiled and deployed on most modern operating systems and hardware configurations (e.g. Windows on ARM, Linux on x86, MacOS on M1). The backend service is also developed with containerization in mind, making it possible to deploy the software securely and avoiding strict dependency on host system configuration.\n\n\n2.1.4 Signal processing and analysis\nOpenRFSense uses a variety of signal processing and analysis techniques to extract useful information from the captured radio frequency signals. This includes techniques such as Fast Fourier Transform (Heideman, Johnson, and Burrus 1984) (FFT), digital signal processing (DSP), and machine learning algorithms. See Section 5.2 for a more in-depth explanation of the data analysis process.\n\n\n2.1.5 User interface and management\nOpenRFSense provides a web-based user interface for configuring, managing, and visualizing the captured data. The user interface includes features such as real-time spectrum displays, signal analysis tools, and alerting mechanisms. The system also provides APIs for integration with external tools and services."
  },
  {
    "objectID": "chapters/system-architecture.html#backend-architecture",
    "href": "chapters/system-architecture.html#backend-architecture",
    "title": "2  System architecture",
    "section": "2.2 Backend architecture",
    "text": "2.2 Backend architecture\nThe backend service is a monolithic application which combines user interface and data management code. It can be broken down into several modular components which all depend only on shared configuration in the form of a file or environment variables on the host system.\nThe internal messaging service maintains a constant communication stream between the backend and the various nodes deployed by the user. It provides a scalable and fault-tolerant solution for message delivery to the remote nodes. It is documented in Chapter 3.\nAnother critical component is the web-based user interface (UI) which is the main interactive mean for the user to communicate with the other components inside the backend service. An in-depth explanation, complete with other high-level considerations, is contained in Chapter 4.\n\n2.2.1 REST API\nTo allow external access to stored data, a REST (REpresentational State Transfer, defined in (R. T. Fielding and Taylor 2000)) API is provided by the backend. Such a system allows authorized applications to query data through a standardized interface. Currently, the following data can be fetched from the backend:\n\nsignal measurements taken by a specific node and belonging to a certain campaign\na list of all nodes currently connected to the messaging system\nnode metrics and system status for a specific node\n\nThe API can also actively request actions to be carried out by the nodes. To ensure bad actors cannot arbitrarily send command requests to the system, all requests which perform an action that can change the state of the system require a form of authentication. The currently implemented authentication method is Basic HTTP Authentication (a Web standard, see (R. Fielding and Reschke 2014)).\n\n\n2.2.2 Signal measurements storage\nSince radio signal data can be dense and structured as large inbound TCP packets, a storage layer capable of extremely fast writes to memory is needed. The BadgerDB (“BadgerDB,” n.d.) key-value store was chosen due to the maturity of the software and it being natively developed in Golang, providing easier integration into the existing backend code. BadgerDB is capable, in optimal conditions (sufficient RAM and a modern solid state disk), of writing several gigabytes of data per second to disk. In practical testing, BadgerDB has proven more than sufficient for handling raw inbound signal data from several nodes at a time.\n\n\n2.2.3 Database access layer\nA support database is used to store persistent data, which is required to survive service outages or is generally better kept for an unspecified amount of time. PostgreSQL (Group 2023) was chosen mainly due to the maturity and notoriety of the project. From the project website:\n\nPostgreSQL is a powerful, open source object-relational database system that uses and extends the SQL language combined with many features that safely store and scale the most complicated data workloads.\n\nPostgreSQL is widely available and easily deployable even using container technology. A native Golang implementation of the database connection and communication protocol is used internally to store data such as past node metrics received through the messaging system, or signal measurement campaign data (start date and time, end date and time, etc.). Such data is then available for querying through the REST API documented above (in Section 2.2.1)."
  },
  {
    "objectID": "chapters/system-architecture.html#node-architecture",
    "href": "chapters/system-architecture.html#node-architecture",
    "title": "2  System architecture",
    "section": "2.3 Node architecture",
    "text": "2.3 Node architecture\nThe node software is developed upon much the same technologies as the backend to ease integration between the two and reduce development overhead. Being developed to run natively on embedded devices as a self-contained application, several software components are needed to fullfil all required functions.\nThe application is available both as a standalone, statically-linked executable and a more user-friendly prebuilt system image based on the Raspbian OS. The system image comes pre-configured with required system components such as:\n\na SystemD (“Systemd,” n.d.) service which starts the node management software on boot\nthe OpenRFSense node management application\nthe external, low-level program which interfaces with the SDR hardware (orfs-sensor)\nsome useful signal decoding software, also part of the project\n\nThe following sections describe the main components of the node management software.\n\n2.3.1 System metrics collector\nA critical component for the node software is the metrics collector. This component is responsible for providing a current snapshot of the status of both hardware and software of the system, which will then be stored by the backend. The metrics message format and message exchange is documented more extensively in Section 3.1.\n\n\n2.3.2 Process manager\nThe node software relies on an external process for data acquisition and delivery. Not being originally developed with integration in mind, such a program is managed as a zero-knowledge black box, executed as a child process by generating command-line arguments and passing them to the program.\n\n\n\n\nmeasurement process flow\n\n\n\n\n\n2.3.3 User interface\nMuch like the backend, the node provides users with a web-based UI to manage system functionality. Additionally, the UI lets users configure and reboot the system without needing an external monitor or peripherals for easier system administration of embedded devices. A description of the node UI with screenshots is contained in Section 4.2.4.\nThe interface is only accessible on the same network as the node, to avoid exposing administration functionality to the public internet. Additionally, for thirty minutes after the system is booted, the UI is accessible by connecting to the device through a temporary WiFi access point if the hardware is capable of creating one such connection.\n\n\n\n\n“BadgerDB.” n.d. https://dgraph.io/docs/badger.\n\n\nFielding, Roy Thomas, and Richard N. Taylor. 2000. “Architectural Styles and the Design of Network-Based Software Architectures.” University of California, Irvine.\n\n\nFielding, R., and J. Reschke. 2014. “Hypertext Transfer Protocol (HTTP/1.1): Authentication.” RFC 7235. RFC Editor / RFC Editor; Internet Requests for Comments. http://www.rfc-editor.org/rfc/rfc7235.txt.\n\n\nGroup, PostgreSQL Global Development. 2023. “PostgreSQL.” PostgreSQL. February 25, 2023. https://www.postgresql.org/.\n\n\nHeideman, M., D. Johnson, and C. Burrus. 1984. “Gauss and the History of the Fast Fourier Transform.” IEEE ASSP Magazine 1 (4): 14–21. https://doi.org/10.1109/MASSP.1984.1162257.\n\n\n“Systemd.” n.d. https://www.freedesktop.org/wiki/Software/systemd/.\n\n\n“The Go Programming Language.” n.d. https://go.dev/."
  },
  {
    "objectID": "chapters/service-messaging.html#sec-metrics",
    "href": "chapters/service-messaging.html#sec-metrics",
    "title": "3  Service messaging",
    "section": "3.1 Node metrics",
    "text": "3.1 Node metrics\nThe backend, when requested through the REST API or the web UI, sends a message to a specific NATS subject (to which all nodes are required to listen on). All nodes then start collecting internal metrics (such as CPU usage and temperature, memory usage etc.) and respond on the same subject with the collected data, encoded in JSON (JavaScript Object Notation) format (ECMA 2017).\n\n\n\n\nFigure 3.1: node metrics request flow\n\n\n\n\n3.1.1 Metrics contents\nA metrics object contains useful system data such as:\n\nthe system hostname\na unique hardware ID derived from the motherboard model\nthe motherboard/hardware model of the system\nthe system’s online time (uptime) in milliseconds since it was powered on\n\nAdditionally, a variable-content section is reserved for less crucial information. This section is never required nor checked by the backend, but its data, if present, is shown to the user through the web UI. Currently, such data is provided by small standardized software modules (), which are called by the node management software if present. Some currently implemented providers are:\n\nnode geographical location in GeoJSON (Butler et al. 2016) format\nfilesystem usage\nmemory (RAM) usage\nnetwork connections\ncurrent node availability (free, busy, handling errors, etc.)\n\n\n\n3.1.2 Message encoding\nAs stated above, node metrics are encoded in JSON format to be easily accessible by external services, since JSON is a well-established industry standard data format. An example of the metrics data encoded in textual JSON is Listing 3.1.\n\nListing 3.1: example metrics object in JSON format\n{\n  \"id\": \"kgslnximugwhsfnwbjknwbv\",\n  \"hostname\": \"raspberry\",\n  \"model\": \"Raspberry Pi 3B\",\n  \"uptime\": 186339250000000,\n  \"providers\": []\n}"
  },
  {
    "objectID": "chapters/service-messaging.html#sec-commands",
    "href": "chapters/service-messaging.html#sec-commands",
    "title": "3  Service messaging",
    "section": "3.2 Commands",
    "text": "3.2 Commands\nThe backend can also publish messages to node-specific subjects. This enables the backend to remotely control the nodes and send configuration updates or commands. The messages can be one of two types:\n\nempty messages sent on a specific NATS subject ()\nJSON-encoded messages containing relevant context for the requested action\n\nWhen a node receives a remote command message, it processes the command and sends a response message back to the backend. The response message can contain any relevant information about the status of the command, such as success or failure, and any associated data. Generally, nodes send their system metrics as response but it is not a strict requirement.\n\n\n\n\nFigure 3.2: sensor campaign command flow\n\n\n\n\n\n\n\nButler, H., M. Daly, A. Doyle, S. Gillies, S. Hagen, and T. Schaub. 2016. “The GeoJSON Format.” RFC 7946. RFC Editor / RFC Editor; Internet Requests for Comments.\n\n\nECMA. 2017. ECMA-404: The JSON Data Interchange Syntax. Geneva, Switzerland: ECMA (European Association for Standardizing Information and Communication Systems). https://www.ecma-international.org/publications-and-standards/standards/ecma-404/.\n\n\n“NATS.” n.d. NATS.io. https://nats.io/about."
  },
  {
    "objectID": "chapters/user-interface.html#design-principles",
    "href": "chapters/user-interface.html#design-principles",
    "title": "4  User interface",
    "section": "4.1 Design principles",
    "text": "4.1 Design principles\nSeveral design principles guided the development of the user interface, mainly:\n\nConsistency: Elements such as fonts, colors, and icons are consistent throughout the interface, making it easier for users to navigate between UI sections and use the system.\nSimplicity: The user interface is simple and easy to use. The simplicity principle ensures that the interface is not cluttered with unnecessary elements, making it easy for users to find what they need.\nFeedback: The user interface provides users with immediate feedback to let them know that their actions have been registered. This principle ensures that users are not left wondering whether their actions have been successful.\nAccessibility: The user interface is designed to be accessible to all users, including those with disabilities. This principle ensures that users with different abilities can use the system without encountering any usability barriers."
  },
  {
    "objectID": "chapters/user-interface.html#interface-components-and-structure",
    "href": "chapters/user-interface.html#interface-components-and-structure",
    "title": "4  User interface",
    "section": "4.2 Interface components and structure",
    "text": "4.2 Interface components and structure\nThe UI is aimed at users with a certain technical background and previous knowledge of the system, but it is designed to be easily navigated through by any given user.\n\n\n\n\nUI hyperlink structure\n\n\n\n\n4.2.1 Dashboard\nThe dashboard acts as the homepage of the UI. It is the first page served by the backend on the root address and is the first interactive element the user will be shown on connection to the system.\n\n\n\nDashboard\n\n\nThe first element presented by the UI is a table containing useful information about all nodes connected to the backend, such as node location and unique identifier. Each node can be selected with a checkbox to take part in a measurement campaign (configurable through a pop-up modal dialog). Every row also contains a link to a page which visualizes a node’s metrics and location in more detail (see Section 4.2.2).\nThe homepage of the UI provides a map of the world, with the locations of all the sensors in the OpenRFSense network indicated by markers. Clicking on the markers yields basic information about each node, such as its ID and the last time it was active, and a link the node-specific overview page.\n\n\n4.2.2 Node overview page\nA node-specific overview page is also generated for each node connected to the backend and the messaging system. This page generally contains all required node metrics returned by a request to the node, as well as more detailed node system information if available (see Section 3.1). The node overview page also contains a map but only showing a single marker corresponding to the node being queried and centered on the node’s location, if provided.\n\n\n\nNode overview page\n\n\nA table containing a list of all past and ongoing measurement campaigns is also provided to the user, with management controls on each row to download the signal data in various formats or delete it from the storage. The controls are non-interactive if the campaign is still ongoing.\n\n\n\n4.2.3 API documentation\nTo make the REST API (defined in Section 2.2.1) easily accessible to users and external applications, a documentation page is automatically generated using Swagger (OpenAPI specification version 2.0 (“OpenAPI Specification - Version 2.0 | Swagger,” n.d.)). The generated page contains all the necessary documentation to query data and send commands to the backend, complete with examples and request and response formats in textual JSON.\n\n\n\nAPI documentation\n\n\n\n\n\n4.2.4 Node system interface\nEach node’s local management UI provides a high-level management over the host system running the node. As such, it must present important information in logical order, starting with connection status (both WiFi and physical). On remote devices, this facilitates troubleshooting and provides an alternative method of restoring connection to a node.\n\n\n\nNode system management page\n\n\nA simple text editor is also provided for the node management software configuration. Each change followed by a click on the “Save” button will write the changes to the configuration file and reboot the system.\n\n\n\n\n\n“OpenAPI Specification - Version 2.0 | Swagger.” n.d. https://swagger.io/specification/v2/."
  },
  {
    "objectID": "chapters/data-collection-and-analysis.html#data-acquisition",
    "href": "chapters/data-collection-and-analysis.html#data-acquisition",
    "title": "5  Data collection and analysis",
    "section": "5.1 Data acquisition",
    "text": "5.1 Data acquisition\nThe node software utilizes a set of low-level hardware APIs to interface with the SDR receiver(s) and collect the RF signals. The main data collection routine is handled by a customized version of a pre-existing Electrosense software, which interfaces with connected SDR devices and streams data towards an external destination.\nThe data is collected in one of two forms:\n\nraw spectral density ordered by frequency\nspectral density averaged over an arbitrary number of seconds using Fast Fourier Transform (FFT)"
  },
  {
    "objectID": "chapters/data-collection-and-analysis.html#sec-signalProcessing",
    "href": "chapters/data-collection-and-analysis.html#sec-signalProcessing",
    "title": "5  Data collection and analysis",
    "section": "5.2 Signal processing",
    "text": "5.2 Signal processing\nThe signal processing component is responsible for cleaning up the collected RF signals and extracting the relevant features for analysis. The component utilizes a set of algorithms to filter out noise and interference from the collected signals. Once the signals are cleaned up, the component extracts relevant features such as the signal strength, modulation type, and frequency. At the time of writing, the following signal encodings can be preprocessed:\n\nAircraft Communications Addressing and Reporting System (ACARS)\nLTE, both User Equipment-to-cell and cell-to-User Equipment\nMode S (Organization 2004) collision avoidance messages\nAeronautical Information Service (AIS) air traffic information\nAM/FM radio"
  },
  {
    "objectID": "chapters/data-collection-and-analysis.html#data-streaming",
    "href": "chapters/data-collection-and-analysis.html#data-streaming",
    "title": "5  Data collection and analysis",
    "section": "5.3 Data streaming",
    "text": "5.3 Data streaming\nThe processed data is serialized in a JSON-based binary format (Apache Avro (“Apache Avro Documentation,” n.d.)), together with extra metadata such as:\n\ntime of recording\nnode hardware identifier and campaign identifier code\nsensor hardware configuration (center frequency, antenna gain, estimated noise floor, etc.)\n\nThe encoded packets are then sent over the Internet to the backend service through several raw TCP connections per receiver to maximize flow. Surprisingly, even low-cost modern SDR receivers tend to output large quantities of data (usually in the order of several megabytes per second). This requires the usage of clever throughput maximization algorithms such as TCP Fast Open (Radhakrishnan et al. 2011) and SO_REUSEPORT."
  },
  {
    "objectID": "chapters/data-collection-and-analysis.html#data-storage",
    "href": "chapters/data-collection-and-analysis.html#data-storage",
    "title": "5  Data collection and analysis",
    "section": "5.4 Data storage",
    "text": "5.4 Data storage\nThe cleaned up and feature-extracted data is received by the backend and partially deserialized to extract the node hardware identifier and campaign identifier code, which are used to derive a unique key for that packet to be used in storage. The binary-encoded data is then stored in a database embedded in the backend for later analysis. The data is written to disk in a structured format that allows for fast querying and analysis. The storage software component is explained in more detail in Section 2.2.2."
  },
  {
    "objectID": "chapters/data-collection-and-analysis.html#analysis-of-spectrum-data",
    "href": "chapters/data-collection-and-analysis.html#analysis-of-spectrum-data",
    "title": "5  Data collection and analysis",
    "section": "5.5 Analysis of spectrum data",
    "text": "5.5 Analysis of spectrum data\nTo analyze the collected spectrum data, several techniques can be employed. One approach is to use statistical methods to identify patterns or anomalies in the data. For example, signal strength and frequency distribution can be analyzed to detect unusual patterns, which may indicate the presence of interference sources. Another approach is to use machine learning algorithms to automatically classify different types of signals based on their frequency, bandwidth, and modulation. This can help to identify different types of signals, such as WiFi, Bluetooth, or cellular signals, and to detect any new or unknown signals.\nOverall, the collected spectrum data is a valuable resource for a wide range of applications. The different techniques for analyzing the data can provide useful insights into the electromagnetic environment, giving users easy access to dense and reasonably accurate research samples.\n\n\n\n\n“Apache Avro Documentation.” n.d. Apache Avro. https://avro.apache.org/docs/.\n\n\nOrganization, International Civil Aviation, ed. 2004. Manual on Mode S Specific Services. 2nd. ed. Montreal: ICAO.\n\n\nRadhakrishnan, Sivasankar, Yuchung Cheng, Jerry Chu, Arvind Jain, and Barath Raghavan. 2011. “TCP Fast Open.” In Proceedings of the Seventh COnference on Emerging Networking EXperiments and Technologies, 1–12. Tokyo Japan: ACM. https://doi.org/10.1145/2079296.2079317."
  },
  {
    "objectID": "chapters/conclusion-and-future-work.html#evaluation-of-system-performance-and-limitations",
    "href": "chapters/conclusion-and-future-work.html#evaluation-of-system-performance-and-limitations",
    "title": "6  Conclusion and future work",
    "section": "6.1 Evaluation of system performance and limitations",
    "text": "6.1 Evaluation of system performance and limitations\nAs with any project, OpenRFSense has its limitations that must be acknowledged. Below are some of the limitations of the project.\n\nCoverage: OpenRFSense relies on users who can install and maintain their own sensors. As a result, there may be regions where the sensor density is low, leading to gaps in the collected data.\nSensor accuracy: The accuracy of the collected data is dependent on the quality of the sensors installed. Low-quality sensors may produce unreliable data that could affect the accuracy of the analysis and interpretation of the collected data.\nSignal interference: Interference from other radio sources can tamper with the accuracy of the collected data. For example, electromagnetic radiation from other devices or sources could create a noisy signal that can be challenging to analyze.\nCost: The cost of installing and maintaining the nodes could be a restraining factor, especially in regions where resources are limited.\nSecurity: The sensors collect data from the environment, and ensuring the security and privacy of the collected data is crucial. The project must ensure that the data collected is not misused or accessed by unauthorized individuals.\nData quality: The data collected may not always be of high quality due to a variety of reasons such as environmental conditions, sensor errors, and data transmission errors. Therefore, it is essential to have mechanisms in place to ensure data quality control and filtering."
  },
  {
    "objectID": "chapters/conclusion-and-future-work.html#applications-of-the-project",
    "href": "chapters/conclusion-and-future-work.html#applications-of-the-project",
    "title": "6  Conclusion and future work",
    "section": "6.2 Applications of the project",
    "text": "6.2 Applications of the project\nThe collected spectrum data can be used for a wide range of applications, including radio frequency interference (RFI) identification, spectrum occupancy measurements, and wireless network planning.\nRFI identification is a major application of spectrum data. OpenRFSense provides a real-time view of the electromagnetic environment, allowing users to detect and locate interference sources. The data can also be used for spectrum monitoring, such as measuring the spectrum occupancy of various frequencies. This information can be used to identify underutilized spectrum bands, which can then be allocated for new services or applications.\nAnother important application of the data is wireless network planning. OpenRFSense provides accurate and up-to-date information on the electromagnetic environment, allowing users to identify optimal locations for wireless access points or base stations. The data can also be used to optimize the configuration of said networks, such as adjusting the transmission power or selecting the most appropriate frequency band.\nHobbyists and researchers have also been able to carry out more complex tasks thanks to SDR receivers, such as satellite tracking and image reception (Peralta et al. 2018). This proves SDR-sourced data to be useful even for longer range and higher gain spectrum analysis."
  },
  {
    "objectID": "chapters/conclusion-and-future-work.html#future-directions-for-research-and-development",
    "href": "chapters/conclusion-and-future-work.html#future-directions-for-research-and-development",
    "title": "6  Conclusion and future work",
    "section": "6.3 Future directions for research and development",
    "text": "6.3 Future directions for research and development\nBeing released as open-source software, OpenRFSense is not intended to be a finished, industrial-grade product. Some future areas in which the project could be improved or may need additional research are the following.\n\nIntegration with other sensor networks: OpenRFSense can be integrated with other sensor networks, such as those monitoring air quality, water quality, and weather. Integration with these networks can provide a more comprehensive picture of the environment and the impact of electromagnetic radiation on it.\nMachine learning and AI: OpenRFSense can be enhanced with machine learning and artificial intelligence (AI) algorithms to improve the accuracy and speed of data analysis. These algorithms can help identify patterns and anomalies in the data and assist in making predictions and recommendations based on the data.\nReal-time monitoring: The current version of OpenRFSense only provides playback of recorded spectrum data. However, further development can be done to improve the latency and accuracy of the system, at the point of providing users with real-time signal visualization. This can require the use of more advanced sensors and improved data transmission technologies.\nVisualization and data analysis tools: OpenRFSense generates a large amount of data, and tools are needed to help users visualize and analyze the data. This can involve the development of new visualization techniques, such as heat maps and trend analysis, as well as ad-hoc data mining tools and other task-specific analysis tools.\nStandardization and data sharing: OpenRFSense can benefit from standardization of data collection and sharing protocols, such as a universal format for spectrum data storage. This can help ensure that data collected by different sensors and networks can be easily shared and combined to provide a more comprehensive picture of the environment.\n\n\n\n\n\nPeralta, David Julian M., Douglas S. Dos Santos, Auro Tikami, Walter A. Dos Santos, and Edson W. R. Pereira. 2018. “Satellite Telemetry and Image Reception with Software Defined Radio Applied to Space Outreach Projects in Brazil.” Anais Da Academia Brasileira de Ciências 90 (3): 3175–84. https://doi.org/10.1590/0001-3765201820170955."
  },
  {
    "objectID": "chapters/appendices.html",
    "href": "chapters/appendices.html",
    "title": "7  Appendices",
    "section": "",
    "text": "8 Code structure\nAll the code for the OpenRFSense project is hosted on Github, a free Git repository hosting service with additional code and community management tools. At the time of writing, the various components are placed in the following repositories under the OpenRFSense organization:\n\nbackend: source code and tooling for the backend service\nnode: source code and tooling for the node management software\norfs-sensor: source code for the signal recording software\nimage: various scripts and tooling to generate the pre-configured system image for Raspberry Pi boards\nopenrfsense.github.io: technical documentation for the project (see Appendix 10)\ncommon: shared code which would otherwise be duplicated in both node and backend\n\n\n\n9 Project branding\nSpecial care was put behind giving an identity to the OpenRFSense project through graphic design. A simple but meaningful logo contains the abbreviated project name and a round symbology reminiscent of WiFi-associated commercial products.\n\n\n\nOfficial OpenRFSense logo\n\n\nThe color palette has enough contrast to be accessible but maintains at least one saturated color.\n\n\n\nColor palette\n\n\n\n\n10 Technical documentation\nAll software components for the OpenRFSense project contain self-documenting code with numerous comments and additional language-specific documentation tooling (godoc). Moreover, additional user-oriented technical documentation has been written and is deployed automatically on Github’s static file hosting service (Github Pages).\nThe documentation is written in Markdown format and is rendered to a static website using the Jekyll program. It includes code blocks with ready-to-use examples to prepare deployments and configure the services before starting the system, together with overviews of the various components. All pages also feature a search widget which facilitates navigation through the text contents.\n\n\n\nOpenRFSense documentation"
  },
  {
    "objectID": "chapters/bibliography.html",
    "href": "chapters/bibliography.html",
    "title": "Bibliography",
    "section": "",
    "text": "“Apache Avro Documentation.” n.d. Apache\nAvro. https://avro.apache.org/docs/.\n\n\n“BadgerDB.” n.d. https://dgraph.io/docs/badger.\n\n\nButler, H., M. Daly, A. Doyle, S. Gillies, S. Hagen, and T. Schaub.\n2016. “The GeoJSON Format.” RFC 7946.\nRFC Editor / RFC Editor; Internet Requests for Comments.\n\n\nECMA. 2017. ECMA-404: The JSON Data\nInterchange Syntax. Geneva, Switzerland: ECMA\n(European Association for Standardizing Information and Communication\nSystems). https://www.ecma-international.org/publications-and-standards/standards/ecma-404/.\n\n\nFielding, Roy Thomas, and Richard N. Taylor. 2000. “Architectural\nStyles and the Design of Network-Based Software Architectures.”\nUniversity of California, Irvine.\n\n\nFielding, R., and J. Reschke. 2014. “Hypertext Transfer Protocol\n(HTTP/1.1): Authentication.” RFC 7235.\nRFC Editor / RFC Editor; Internet Requests for Comments. http://www.rfc-editor.org/rfc/rfc7235.txt.\n\n\nGroup, PostgreSQL Global Development. 2023.\n“PostgreSQL.” PostgreSQL.\nFebruary 25, 2023. https://www.postgresql.org/.\n\n\nHeideman, M., D. Johnson, and C. Burrus. 1984. “Gauss and the\nHistory of the Fast Fourier Transform.” IEEE ASSP\nMagazine 1 (4): 14–21. https://doi.org/10.1109/MASSP.1984.1162257.\n\n\n“NATS.” n.d. NATS.io. https://nats.io/about.\n\n\n“OpenAPI Specification - Version 2.0 |\nSwagger.” n.d. https://swagger.io/specification/v2/.\n\n\nOrganization, International Civil Aviation, ed. 2004. Manual on Mode\nS Specific Services. 2nd. ed. Montreal:\nICAO.\n\n\nPeralta, David Julian M., Douglas S. Dos Santos, Auro Tikami, Walter A.\nDos Santos, and Edson W. R. Pereira. 2018. “Satellite\nTelemetry and Image Reception with\nSoftware Defined Radio Applied to Space Outreach\nProjects in Brazil.” Anais Da Academia\nBrasileira de Ciências 90 (3): 3175–84. https://doi.org/10.1590/0001-3765201820170955.\n\n\nRadhakrishnan, Sivasankar, Yuchung Cheng, Jerry Chu, Arvind Jain, and\nBarath Raghavan. 2011. “TCP Fast Open.” In\nProceedings of the Seventh COnference on Emerging\nNetworking EXperiments and Technologies,\n1–12. Tokyo Japan: ACM. https://doi.org/10.1145/2079296.2079317.\n\n\n“Systemd.” n.d. https://www.freedesktop.org/wiki/Software/systemd/.\n\n\n“The Go Programming Language.” n.d. https://go.dev/."
  }
]