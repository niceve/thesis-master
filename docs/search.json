[
  {
    "objectID": "chapters/appendices.html",
    "href": "chapters/appendices.html",
    "title": "1 Appendices",
    "section": "",
    "text": "1 Appendices\n\n\n\n2 Code structure\nAll the code for the OpenRFSense project is hosted on Github, a free Git repository hosting service with additional code and community management tools. At the time of writing, the various components are placed in the following repositories under the OpenRFSense organization:\n\nbackend: source code and tooling for the backend service\nnode: source code and tooling for the node management software\norfs-sensor: source code for the signal recording software\nimage: various scripts and tooling to generate the pre-configured system image for Raspberry Pi boards\nopenrfsense.github.io: technical documentation for the project (see Appendix 4)\ncommon: shared code which would otherwise be duplicated in both node and backend\n\n\n\n3 Project branding\nSpecial care was put behind giving an identity to the OpenRFSense project through graphic design. A simple but meaningful logo contains the abbreviated project name and a round symbology reminiscent of WiFi-associated commercial products.\n\n\n\nOfficial OpenRFSense logo\n\n\nThe color palette has enough contrast to be accessible but maintains at least one saturated color.\n\n\n\nColor palette\n\n\n\n\n4 Technical documentation\nAll software components for the OpenRFSense project contain self-documenting code with numerous comments and additional language-specific documentation tooling (godoc). Moreover, additional user-oriented technical documentation has been written and is deployed automatically on Github’s static file hosting service (Github Pages).\nThe documentation is written in Markdown format and is rendered to a static website using the Jekyll program. It includes code blocks with ready-to-use examples to prepare deployments and configure the services before starting the system, together with overviews of the various components. All pages also feature a search widget which facilitates navigation through the text contents.\n\n\n\nOpenRFSense documentation"
  },
  {
    "objectID": "chapters/bibliography.html",
    "href": "chapters/bibliography.html",
    "title": "Bibliography",
    "section": "",
    "text": "Bibliography"
  },
  {
    "objectID": "chapters/conclusion-and-future-work.html",
    "href": "chapters/conclusion-and-future-work.html",
    "title": "1 Conclusion and future work",
    "section": "",
    "text": "OpenRFSense was developed as an experimental software suite powered by modern software-defined radio technology. The following sections contain some closing remarks and reflections about the project and the status of the SDR-based data analysis as a whole.\n\n\nAs with any project, OpenRFSense has its limitations that must be acknowledged. Below are some of the limitations of the project.\n\nCoverage: OpenRFSense relies on users who can install and maintain their own sensors. As a result, there may be regions where the sensor density is low, leading to gaps in the collected data.\nSensor accuracy: The accuracy of the collected data is dependent on the quality of the sensors installed. Low-quality sensors may produce unreliable data that could affect the accuracy of the analysis and interpretation of the collected data.\nSignal interference: Interference from other radio sources can tamper with the accuracy of the collected data. For example, electromagnetic radiation from other devices or sources could create a noisy signal that can be challenging to analyze.\nCost: The cost of installing and maintaining the nodes could be a restraining factor, especially in regions where resources are limited.\nSecurity: The sensors collect data from the environment, and ensuring the security and privacy of the collected data is crucial. The project must ensure that the data collected is not misused or accessed by unauthorized individuals.\nData quality: The data collected may not always be of high quality due to a variety of reasons such as environmental conditions, sensor errors, and data transmission errors. Therefore, it is essential to have mechanisms in place to ensure data quality control and filtering.\n\n\n\n\nThe collected spectrum data can be used for a wide range of applications, including radio frequency interference (RFI) identification, spectrum occupancy measurements, and wireless network planning.\nRFI identification is a major application of spectrum data. OpenRFSense provides a real-time view of the electromagnetic environment, allowing users to detect and locate interference sources. The data can also be used for spectrum monitoring, such as measuring the spectrum occupancy of various frequencies. This information can be used to identify underutilized spectrum bands, which can then be allocated for new services or applications.\nAnother important application of the data is wireless network planning. OpenRFSense provides accurate and up-to-date information on the electromagnetic environment, allowing users to identify optimal locations for wireless access points or base stations. The data can also be used to optimize the configuration of said networks, such as adjusting the transmission power or selecting the most appropriate frequency band.\nHobbyists and researchers have also been able to carry out more complex tasks thanks to SDR receivers, such as satellite tracking and image reception (Peralta et al. 2018). This proves SDR-sourced data to be useful even for longer range and higher gain spectrum analysis.\n\n\n\nBeing released as open-source software, OpenRFSense is not intended to be a finished, industrial-grade product. Some future areas in which the project could be improved or may need additional research are the following.\n\nIntegration with other sensor networks: OpenRFSense can be integrated with other sensor networks, such as those monitoring air quality, water quality, and weather. Integration with these networks can provide a more comprehensive picture of the environment and the impact of electromagnetic radiation on it.\nMachine learning and AI: OpenRFSense can be enhanced with machine learning and artificial intelligence (AI) algorithms to improve the accuracy and speed of data analysis. These algorithms can help identify patterns and anomalies in the data and assist in making predictions and recommendations based on the data.\nReal-time monitoring: The current version of OpenRFSense only provides playback of recorded spectrum data. However, further development can be done to improve the latency and accuracy of the system, at the point of providing users with real-time signal visualization. This can require the use of more advanced sensors and improved data transmission technologies.\nVisualization and data analysis tools: OpenRFSense generates a large amount of data, and tools are needed to help users visualize and analyze the data. This can involve the development of new visualization techniques, such as heat maps and trend analysis, as well as ad-hoc data mining tools and other task-specific analysis tools.\nStandardization and data sharing: OpenRFSense can benefit from standardization of data collection and sharing protocols, such as a universal format for spectrum data storage. This can help ensure that data collected by different sensors and networks can be easily shared and combined to provide a more comprehensive picture of the environment.\n\n\n\n\n\nPeralta, David Julian M., Douglas S. Dos Santos, Auro Tikami, Walter A. Dos Santos, and Edson W. R. Pereira. 2018. “Satellite Telemetry and Image Reception with Software Defined Radio Applied to Space Outreach Projects in Brazil.” Anais Da Academia Brasileira de Ciências 90 (3): 3175–84. https://doi.org/10.1590/0001-3765201820170955."
  },
  {
    "objectID": "chapters/conclusion-and-future-work.html#evaluation-of-system-performance-and-limitations",
    "href": "chapters/conclusion-and-future-work.html#evaluation-of-system-performance-and-limitations",
    "title": "1 Conclusion and future work",
    "section": "",
    "text": "As with any project, OpenRFSense has its limitations that must be acknowledged. Below are some of the limitations of the project.\n\nCoverage: OpenRFSense relies on users who can install and maintain their own sensors. As a result, there may be regions where the sensor density is low, leading to gaps in the collected data.\nSensor accuracy: The accuracy of the collected data is dependent on the quality of the sensors installed. Low-quality sensors may produce unreliable data that could affect the accuracy of the analysis and interpretation of the collected data.\nSignal interference: Interference from other radio sources can tamper with the accuracy of the collected data. For example, electromagnetic radiation from other devices or sources could create a noisy signal that can be challenging to analyze.\nCost: The cost of installing and maintaining the nodes could be a restraining factor, especially in regions where resources are limited.\nSecurity: The sensors collect data from the environment, and ensuring the security and privacy of the collected data is crucial. The project must ensure that the data collected is not misused or accessed by unauthorized individuals.\nData quality: The data collected may not always be of high quality due to a variety of reasons such as environmental conditions, sensor errors, and data transmission errors. Therefore, it is essential to have mechanisms in place to ensure data quality control and filtering."
  },
  {
    "objectID": "chapters/conclusion-and-future-work.html#applications-of-the-project",
    "href": "chapters/conclusion-and-future-work.html#applications-of-the-project",
    "title": "1 Conclusion and future work",
    "section": "",
    "text": "The collected spectrum data can be used for a wide range of applications, including radio frequency interference (RFI) identification, spectrum occupancy measurements, and wireless network planning.\nRFI identification is a major application of spectrum data. OpenRFSense provides a real-time view of the electromagnetic environment, allowing users to detect and locate interference sources. The data can also be used for spectrum monitoring, such as measuring the spectrum occupancy of various frequencies. This information can be used to identify underutilized spectrum bands, which can then be allocated for new services or applications.\nAnother important application of the data is wireless network planning. OpenRFSense provides accurate and up-to-date information on the electromagnetic environment, allowing users to identify optimal locations for wireless access points or base stations. The data can also be used to optimize the configuration of said networks, such as adjusting the transmission power or selecting the most appropriate frequency band.\nHobbyists and researchers have also been able to carry out more complex tasks thanks to SDR receivers, such as satellite tracking and image reception (Peralta et al. 2018). This proves SDR-sourced data to be useful even for longer range and higher gain spectrum analysis."
  },
  {
    "objectID": "chapters/conclusion-and-future-work.html#future-directions-for-research-and-development",
    "href": "chapters/conclusion-and-future-work.html#future-directions-for-research-and-development",
    "title": "1 Conclusion and future work",
    "section": "",
    "text": "Being released as open-source software, OpenRFSense is not intended to be a finished, industrial-grade product. Some future areas in which the project could be improved or may need additional research are the following.\n\nIntegration with other sensor networks: OpenRFSense can be integrated with other sensor networks, such as those monitoring air quality, water quality, and weather. Integration with these networks can provide a more comprehensive picture of the environment and the impact of electromagnetic radiation on it.\nMachine learning and AI: OpenRFSense can be enhanced with machine learning and artificial intelligence (AI) algorithms to improve the accuracy and speed of data analysis. These algorithms can help identify patterns and anomalies in the data and assist in making predictions and recommendations based on the data.\nReal-time monitoring: The current version of OpenRFSense only provides playback of recorded spectrum data. However, further development can be done to improve the latency and accuracy of the system, at the point of providing users with real-time signal visualization. This can require the use of more advanced sensors and improved data transmission technologies.\nVisualization and data analysis tools: OpenRFSense generates a large amount of data, and tools are needed to help users visualize and analyze the data. This can involve the development of new visualization techniques, such as heat maps and trend analysis, as well as ad-hoc data mining tools and other task-specific analysis tools.\nStandardization and data sharing: OpenRFSense can benefit from standardization of data collection and sharing protocols, such as a universal format for spectrum data storage. This can help ensure that data collected by different sensors and networks can be easily shared and combined to provide a more comprehensive picture of the environment.\n\n\n\n\n\nPeralta, David Julian M., Douglas S. Dos Santos, Auro Tikami, Walter A. Dos Santos, and Edson W. R. Pereira. 2018. “Satellite Telemetry and Image Reception with Software Defined Radio Applied to Space Outreach Projects in Brazil.” Anais Da Academia Brasileira de Ciências 90 (3): 3175–84. https://doi.org/10.1590/0001-3765201820170955."
  },
  {
    "objectID": "chapters/data-collection-and-analysis.html",
    "href": "chapters/data-collection-and-analysis.html",
    "title": "1 Data collection and analysis",
    "section": "",
    "text": "Data collection is at the core of the OpenRFSense project and, as such, requires some complex and specialized components. Overall, the data collection procedure can be better explained as an ordered pipeline, which starts from the remote node.\n\n\nThe node software utilizes a set of low-level hardware APIs to interface with the SDR receiver(s) and collect the RF signals. The main data collection routine is handled by a customized version of a pre-existing Electrosense software, which interfaces with connected SDR devices and streams data towards an external destination.\nThe data is collected in one of two forms:\n\nraw spectral density ordered by frequency\nspectral density averaged over an arbitrary number of seconds using Fast Fourier Transform (FFT)\n\n\n\n\nThe signal processing component is responsible for cleaning up the collected RF signals and extracting the relevant features for analysis. The component utilizes a set of algorithms to filter out noise and interference from the collected signals. Once the signals are cleaned up, the component extracts relevant features such as the signal strength, modulation type, and frequency. At the time of writing, the following signal encodings can be preprocessed:\n\nAircraft Communications Addressing and Reporting System (ACARS)\nLTE, both User Equipment-to-cell and cell-to-User Equipment\nMode S (Organization 2004) collision avoidance messages\nAeronautical Information Service (AIS) air traffic information\nAM/FM radio\n\n\n\n\nThe processed data is serialized in a JSON-based binary format (Apache Avro (“Apache Avro Documentation,” n.d.)), together with extra metadata such as:\n\ntime of recording\nnode hardware identifier and campaign identifier code\nsensor hardware configuration (center frequency, antenna gain, estimated noise floor, etc.)\n\nThe encoded packets are then sent over the Internet to the backend service through several raw TCP connections per receiver to maximize flow. Surprisingly, even low-cost modern SDR receivers tend to output large quantities of data (usually in the order of several megabytes per second). This requires the usage of clever throughput maximization algorithms such as TCP Fast Open (Radhakrishnan et al. 2011) and SO_REUSEPORT.\n\n\n\nThe cleaned up and feature-extracted data is received by the backend and partially deserialized to extract the node hardware identifier and campaign identifier code, which are used to derive a unique key for that packet to be used in storage. The binary-encoded data is then stored in a database embedded in the backend for later analysis. The data is written to disk in a structured format that allows for fast querying and analysis. The storage software component is explained in more detail in ?@sec-signalStorage.\n\n\n\nTo analyze the collected spectrum data, several techniques can be employed. One approach is to use statistical methods to identify patterns or anomalies in the data. For example, signal strength and frequency distribution can be analyzed to detect unusual patterns, which may indicate the presence of interference sources. Another approach is to use machine learning algorithms to automatically classify different types of signals based on their frequency, bandwidth, and modulation. This can help to identify different types of signals, such as WiFi, Bluetooth, or cellular signals, and to detect any new or unknown signals.\nOverall, the collected spectrum data is a valuable resource for a wide range of applications. The different techniques for analyzing the data can provide useful insights into the electromagnetic environment, giving users easy access to dense and reasonably accurate research samples.\n\n\n\n\n“Apache Avro Documentation.” n.d. Apache Avro. https://avro.apache.org/docs/.\n\n\nOrganization, International Civil Aviation, ed. 2004. Manual on Mode S Specific Services. 2nd. ed. Montreal: ICAO.\n\n\nRadhakrishnan, Sivasankar, Yuchung Cheng, Jerry Chu, Arvind Jain, and Barath Raghavan. 2011. “TCP Fast Open.” In Proceedings of the Seventh COnference on Emerging Networking EXperiments and Technologies, 1–12. Tokyo Japan: ACM. https://doi.org/10.1145/2079296.2079317."
  },
  {
    "objectID": "chapters/data-collection-and-analysis.html#data-acquisition",
    "href": "chapters/data-collection-and-analysis.html#data-acquisition",
    "title": "1 Data collection and analysis",
    "section": "",
    "text": "The node software utilizes a set of low-level hardware APIs to interface with the SDR receiver(s) and collect the RF signals. The main data collection routine is handled by a customized version of a pre-existing Electrosense software, which interfaces with connected SDR devices and streams data towards an external destination.\nThe data is collected in one of two forms:\n\nraw spectral density ordered by frequency\nspectral density averaged over an arbitrary number of seconds using Fast Fourier Transform (FFT)"
  },
  {
    "objectID": "chapters/data-collection-and-analysis.html#sec-signalProcessing",
    "href": "chapters/data-collection-and-analysis.html#sec-signalProcessing",
    "title": "1 Data collection and analysis",
    "section": "",
    "text": "The signal processing component is responsible for cleaning up the collected RF signals and extracting the relevant features for analysis. The component utilizes a set of algorithms to filter out noise and interference from the collected signals. Once the signals are cleaned up, the component extracts relevant features such as the signal strength, modulation type, and frequency. At the time of writing, the following signal encodings can be preprocessed:\n\nAircraft Communications Addressing and Reporting System (ACARS)\nLTE, both User Equipment-to-cell and cell-to-User Equipment\nMode S (Organization 2004) collision avoidance messages\nAeronautical Information Service (AIS) air traffic information\nAM/FM radio"
  },
  {
    "objectID": "chapters/data-collection-and-analysis.html#data-streaming",
    "href": "chapters/data-collection-and-analysis.html#data-streaming",
    "title": "1 Data collection and analysis",
    "section": "",
    "text": "The processed data is serialized in a JSON-based binary format (Apache Avro (“Apache Avro Documentation,” n.d.)), together with extra metadata such as:\n\ntime of recording\nnode hardware identifier and campaign identifier code\nsensor hardware configuration (center frequency, antenna gain, estimated noise floor, etc.)\n\nThe encoded packets are then sent over the Internet to the backend service through several raw TCP connections per receiver to maximize flow. Surprisingly, even low-cost modern SDR receivers tend to output large quantities of data (usually in the order of several megabytes per second). This requires the usage of clever throughput maximization algorithms such as TCP Fast Open (Radhakrishnan et al. 2011) and SO_REUSEPORT."
  },
  {
    "objectID": "chapters/data-collection-and-analysis.html#data-storage",
    "href": "chapters/data-collection-and-analysis.html#data-storage",
    "title": "1 Data collection and analysis",
    "section": "",
    "text": "The cleaned up and feature-extracted data is received by the backend and partially deserialized to extract the node hardware identifier and campaign identifier code, which are used to derive a unique key for that packet to be used in storage. The binary-encoded data is then stored in a database embedded in the backend for later analysis. The data is written to disk in a structured format that allows for fast querying and analysis. The storage software component is explained in more detail in ?@sec-signalStorage."
  },
  {
    "objectID": "chapters/data-collection-and-analysis.html#analysis-of-spectrum-data",
    "href": "chapters/data-collection-and-analysis.html#analysis-of-spectrum-data",
    "title": "1 Data collection and analysis",
    "section": "",
    "text": "To analyze the collected spectrum data, several techniques can be employed. One approach is to use statistical methods to identify patterns or anomalies in the data. For example, signal strength and frequency distribution can be analyzed to detect unusual patterns, which may indicate the presence of interference sources. Another approach is to use machine learning algorithms to automatically classify different types of signals based on their frequency, bandwidth, and modulation. This can help to identify different types of signals, such as WiFi, Bluetooth, or cellular signals, and to detect any new or unknown signals.\nOverall, the collected spectrum data is a valuable resource for a wide range of applications. The different techniques for analyzing the data can provide useful insights into the electromagnetic environment, giving users easy access to dense and reasonably accurate research samples.\n\n\n\n\n“Apache Avro Documentation.” n.d. Apache Avro. https://avro.apache.org/docs/.\n\n\nOrganization, International Civil Aviation, ed. 2004. Manual on Mode S Specific Services. 2nd. ed. Montreal: ICAO.\n\n\nRadhakrishnan, Sivasankar, Yuchung Cheng, Jerry Chu, Arvind Jain, and Barath Raghavan. 2011. “TCP Fast Open.” In Proceedings of the Seventh COnference on Emerging Networking EXperiments and Technologies, 1–12. Tokyo Japan: ACM. https://doi.org/10.1145/2079296.2079317."
  },
  {
    "objectID": "chapters/introduction.html",
    "href": "chapters/introduction.html",
    "title": "1 Introduction",
    "section": "",
    "text": "The collection and analysis of data samples from the radio frequency spectrum has always required considerable effort, even with partial automation, due to the inherent complexity and density of such data. Furthermore, complex systems based on analogic circuits were needed to process radio signals. This used to entail large investments in both manpower and capital at any scale, making spectrum analysis infeasible for hobbyists.\nThis thesis will elaborate on the potential of SDR technology and the value of open source software in advancing the field of radio communication systems.\n\n\nSoftware-defined radio (SDR) is a technology that has been gaining attention in recent years due to its ability to revolutionize the way we design and operate radio communication systems. The history of SDR technology can be traced back to the 1980s, when advances in digital signal processing (DSP) made it possible to perform signal processing in software. At that time, SDR was still in its early stages, and the hardware technology available was limited. In the early 1990s, the first SDR prototypes were developed (Mitola 1992), and the technology began to be used in military and defense applications.\nAs the technology progressed, the cost of digital signal processors and memory decreased, and software became more advanced. This allowed for the development of more modern SDR systems which could support a wider range of radio communication protocols and waveforms. In the late 1990s and early 2000s, SDR technology began to be adopted in the commercial sector for applications such as wireless networking and cellular communication systems.\nToday, SDR technology is being used in a wide range of applications, from amateur radio to satellite communication systems, and is increasingly becoming more accessible to the general public. SDR technology is a key enabler for emerging technologies such as the Internet of Things (IoT) and 5G communication systems. The potential benefits of SDR technology are significant, including greater flexibility, reduced development time and cost, and improved spectrum utilization.\nIn today’s world, radio frequency (RF) communication is the backbone of many critical infrastructures, with applications ranging from wireless networking to cellular communication systems. However, the increasing demand for wireless communication has led to a shortage of available spectrum, which can lead to interference and other problems. With this in mind, the motivation behind developing the OpenRFsense project is to create an experimental solution using modern SDR technologies for real-time spectrum monitoring and analysis.\n\n\n\nThe OpenRFSense project leverages a small, high-availability application () running on low-power devices (e.g. a Raspberry Pi or similar single-board computers) equipped with a SDR module and a backend service which provides centralized storage and remote control capabilities over said hardware.\nThe node application is designed to start on boot and run as long as the device is powered on. It’s responsible for communicating useful data to the backend service on demand (such as device telemetry and radio spectrum recordings) and provide a web-based management interface aimed at facilitating normal device configuration without requiring external peripherals to be attached.\nThe backend service is responsible for receiving and storing spectrum data, while also providing a web-based user interface (UI). The service exposes a REST (Fielding and Taylor 2000) interface to make data accessible to external services, while the UI allows users to manage the stored data and explore it by visualizing a playback of the recorded radio spectrum.\n\n\n\nIn recent years many SDR-powered projects have been created to monitor the spectrum in real time. One of such projects is Electrosense (Rajendran et al. 2018), developed independently by a team of researchers. Electrosense is a commercial product which includes a web-based visualization interface for spectrum data and receives such data by means of a custom-designed SDR board attached to a Raspberry Pi computer.\nAnother similar but simpler project is OpenWebRX (Retzler and Ketterl 2018), another web-based spectrum visualization platform which mainly focuses on real-time audiovisual analysis of data through a waterfall plot and noise sampling. The OpenWebRX project only supports visualizing a single data source at a time, but provides a free directory listing of all public machines which provide radio data and a hyperlink leading to their web interface.\n\n\n\n\nFielding, Roy Thomas, and Richard N. Taylor. 2000. “Architectural Styles and the Design of Network-Based Software Architectures.” University of California, Irvine.\n\n\nMitola, J. 1992. “Software Radios-Survey, Critical Evaluation and Future Directions.” In [Proceedings] NTC-92: National Telesystems Conference, 13/15–23. Washington, DC, USA: IEEE. https://doi.org/10.1109/NTC.1992.267870.\n\n\nRajendran, Sreeraj, Roberto Calvo-Palomino, Markus Fuchs, Bertold Van den Bergh, Hector Cordobes, Domenico Giustiniano, Sofie Pollin, and Vincent Lenders. 2018. “Electrosense: Open and Big Spectrum Data.” IEEE Communications Magazine 56 (1): 210–17. https://doi.org/10.1109/MCOM.2017.1700200.\n\n\nRetzler, András, and Jakob Ketterl. 2018. “OpenWebRX Web-Based Software Defined Radio.” 2018. https://www.openwebrx.de."
  },
  {
    "objectID": "chapters/introduction.html#background-and-motivation",
    "href": "chapters/introduction.html#background-and-motivation",
    "title": "1 Introduction",
    "section": "",
    "text": "Software-defined radio (SDR) is a technology that has been gaining attention in recent years due to its ability to revolutionize the way we design and operate radio communication systems. The history of SDR technology can be traced back to the 1980s, when advances in digital signal processing (DSP) made it possible to perform signal processing in software. At that time, SDR was still in its early stages, and the hardware technology available was limited. In the early 1990s, the first SDR prototypes were developed (Mitola 1992), and the technology began to be used in military and defense applications.\nAs the technology progressed, the cost of digital signal processors and memory decreased, and software became more advanced. This allowed for the development of more modern SDR systems which could support a wider range of radio communication protocols and waveforms. In the late 1990s and early 2000s, SDR technology began to be adopted in the commercial sector for applications such as wireless networking and cellular communication systems.\nToday, SDR technology is being used in a wide range of applications, from amateur radio to satellite communication systems, and is increasingly becoming more accessible to the general public. SDR technology is a key enabler for emerging technologies such as the Internet of Things (IoT) and 5G communication systems. The potential benefits of SDR technology are significant, including greater flexibility, reduced development time and cost, and improved spectrum utilization.\nIn today’s world, radio frequency (RF) communication is the backbone of many critical infrastructures, with applications ranging from wireless networking to cellular communication systems. However, the increasing demand for wireless communication has led to a shortage of available spectrum, which can lead to interference and other problems. With this in mind, the motivation behind developing the OpenRFsense project is to create an experimental solution using modern SDR technologies for real-time spectrum monitoring and analysis."
  },
  {
    "objectID": "chapters/introduction.html#project-overview",
    "href": "chapters/introduction.html#project-overview",
    "title": "1 Introduction",
    "section": "",
    "text": "The OpenRFSense project leverages a small, high-availability application () running on low-power devices (e.g. a Raspberry Pi or similar single-board computers) equipped with a SDR module and a backend service which provides centralized storage and remote control capabilities over said hardware.\nThe node application is designed to start on boot and run as long as the device is powered on. It’s responsible for communicating useful data to the backend service on demand (such as device telemetry and radio spectrum recordings) and provide a web-based management interface aimed at facilitating normal device configuration without requiring external peripherals to be attached.\nThe backend service is responsible for receiving and storing spectrum data, while also providing a web-based user interface (UI). The service exposes a REST (Fielding and Taylor 2000) interface to make data accessible to external services, while the UI allows users to manage the stored data and explore it by visualizing a playback of the recorded radio spectrum."
  },
  {
    "objectID": "chapters/introduction.html#related-work",
    "href": "chapters/introduction.html#related-work",
    "title": "1 Introduction",
    "section": "",
    "text": "In recent years many SDR-powered projects have been created to monitor the spectrum in real time. One of such projects is Electrosense (Rajendran et al. 2018), developed independently by a team of researchers. Electrosense is a commercial product which includes a web-based visualization interface for spectrum data and receives such data by means of a custom-designed SDR board attached to a Raspberry Pi computer.\nAnother similar but simpler project is OpenWebRX (Retzler and Ketterl 2018), another web-based spectrum visualization platform which mainly focuses on real-time audiovisual analysis of data through a waterfall plot and noise sampling. The OpenWebRX project only supports visualizing a single data source at a time, but provides a free directory listing of all public machines which provide radio data and a hyperlink leading to their web interface.\n\n\n\n\nFielding, Roy Thomas, and Richard N. Taylor. 2000. “Architectural Styles and the Design of Network-Based Software Architectures.” University of California, Irvine.\n\n\nMitola, J. 1992. “Software Radios-Survey, Critical Evaluation and Future Directions.” In [Proceedings] NTC-92: National Telesystems Conference, 13/15–23. Washington, DC, USA: IEEE. https://doi.org/10.1109/NTC.1992.267870.\n\n\nRajendran, Sreeraj, Roberto Calvo-Palomino, Markus Fuchs, Bertold Van den Bergh, Hector Cordobes, Domenico Giustiniano, Sofie Pollin, and Vincent Lenders. 2018. “Electrosense: Open and Big Spectrum Data.” IEEE Communications Magazine 56 (1): 210–17. https://doi.org/10.1109/MCOM.2017.1700200.\n\n\nRetzler, András, and Jakob Ketterl. 2018. “OpenWebRX Web-Based Software Defined Radio.” 2018. https://www.openwebrx.de."
  },
  {
    "objectID": "chapters/service-messaging.html",
    "href": "chapters/service-messaging.html",
    "title": "1 Service messaging",
    "section": "",
    "text": "In OpenRFSense, NATS messaging (“NATS,” n.d.) is used to enable communication between the backend and the nodes. NATS (Neural Autonomic Transport System) is a lightweight messaging system that is commonly used for machine-to-machine (M2M) communication in IoT (Internet of Things) applications. A messaging system such as NATS is based on message delivery guarantees and optional message retention for later delivery. These capabilities ensure service message resiliency through high-latency connections and in-flight data loss.\nThe backend acts as the NATS server and the nodes act as NATS clients which connect to the server. When a node is powered on, it connects to the NATS server and subscribes to a , which is a named destination to which messages are published. The node can subscribe to one or more subjects depending on its capabilities. Some subjects currently being used for service messages are:\n\nnode.all for node system metrics (see Section 1.1)\nnode.all.aggregated and node.all.raw for backend-to-node signal recording commands (see Section 1.2)\nnode.$hardware_id.$command, where $hardware_id is the node’s unique identifier and $command is a specific action being requested\n\n\n\nThe backend, when requested through the REST API or the web UI, sends a message to a specific NATS subject (to which all nodes are required to listen on). All nodes then start collecting internal metrics (such as CPU usage and temperature, memory usage etc.) and respond on the same subject with the collected data, encoded in JSON (JavaScript Object Notation) format (ECMA 2017).\n\n\n\n\nFigure 1.1: node metrics request flow\n\n\n\n\n\nA metrics object contains useful system data such as:\n\nthe system hostname\na unique hardware ID derived from the motherboard model\nthe motherboard/hardware model of the system\nthe system’s online time (uptime) in milliseconds since it was powered on\n\nAdditionally, a variable-content section is reserved for less crucial information. This section is never required nor checked by the backend, but its data, if present, is shown to the user through the web UI. Currently, such data is provided by small standardized software modules (), which are called by the node management software if present. Some currently implemented providers are:\n\nnode geographical location in GeoJSON (Butler et al. 2016) format\nfilesystem usage\nmemory (RAM) usage\nnetwork connections\ncurrent node availability (free, busy, handling errors, etc.)\n\n\n\n\nAs stated above, node metrics are encoded in JSON format to be easily accessible by external services, since JSON is a well-established industry standard data format. An example of the metrics data encoded in textual JSON is Listing 1.1.\n\nListing 1.1: example metrics object in JSON format\n{\n  \"id\": \"kgslnximugwhsfnwbjknwbv\",\n  \"hostname\": \"raspberry\",\n  \"model\": \"Raspberry Pi 3B\",\n  \"uptime\": 186339250000000,\n  \"providers\": []\n}\n\n\n\n\n\nThe backend can also publish messages to node-specific subjects. This enables the backend to remotely control the nodes and send configuration updates or commands. The messages can be one of two types:\n\nempty messages sent on a specific NATS subject ()\nJSON-encoded messages containing relevant context for the requested action\n\nWhen a node receives a remote command message, it processes the command and sends a response message back to the backend. The response message can contain any relevant information about the status of the command, such as success or failure, and any associated data. Generally, nodes send their system metrics as response but it is not a strict requirement.\n\n\n\n\nFigure 1.2: sensor campaign command flow\n\n\n\n\n\n\n\nButler, H., M. Daly, A. Doyle, S. Gillies, S. Hagen, and T. Schaub. 2016. “The GeoJSON Format.” RFC 7946. RFC Editor / RFC Editor; Internet Requests for Comments.\n\n\nECMA. 2017. ECMA-404: The JSON Data Interchange Syntax. Geneva, Switzerland: ECMA (European Association for Standardizing Information and Communication Systems). https://www.ecma-international.org/publications-and-standards/standards/ecma-404/.\n\n\n“NATS.” n.d. NATS.io. https://nats.io/about."
  },
  {
    "objectID": "chapters/service-messaging.html#sec-metrics",
    "href": "chapters/service-messaging.html#sec-metrics",
    "title": "1 Service messaging",
    "section": "",
    "text": "The backend, when requested through the REST API or the web UI, sends a message to a specific NATS subject (to which all nodes are required to listen on). All nodes then start collecting internal metrics (such as CPU usage and temperature, memory usage etc.) and respond on the same subject with the collected data, encoded in JSON (JavaScript Object Notation) format (ECMA 2017).\n\n\n\n\nFigure 1.1: node metrics request flow\n\n\n\n\n\nA metrics object contains useful system data such as:\n\nthe system hostname\na unique hardware ID derived from the motherboard model\nthe motherboard/hardware model of the system\nthe system’s online time (uptime) in milliseconds since it was powered on\n\nAdditionally, a variable-content section is reserved for less crucial information. This section is never required nor checked by the backend, but its data, if present, is shown to the user through the web UI. Currently, such data is provided by small standardized software modules (), which are called by the node management software if present. Some currently implemented providers are:\n\nnode geographical location in GeoJSON (Butler et al. 2016) format\nfilesystem usage\nmemory (RAM) usage\nnetwork connections\ncurrent node availability (free, busy, handling errors, etc.)\n\n\n\n\nAs stated above, node metrics are encoded in JSON format to be easily accessible by external services, since JSON is a well-established industry standard data format. An example of the metrics data encoded in textual JSON is Listing 1.1.\n\nListing 1.1: example metrics object in JSON format\n{\n  \"id\": \"kgslnximugwhsfnwbjknwbv\",\n  \"hostname\": \"raspberry\",\n  \"model\": \"Raspberry Pi 3B\",\n  \"uptime\": 186339250000000,\n  \"providers\": []\n}"
  },
  {
    "objectID": "chapters/service-messaging.html#sec-commands",
    "href": "chapters/service-messaging.html#sec-commands",
    "title": "1 Service messaging",
    "section": "",
    "text": "The backend can also publish messages to node-specific subjects. This enables the backend to remotely control the nodes and send configuration updates or commands. The messages can be one of two types:\n\nempty messages sent on a specific NATS subject ()\nJSON-encoded messages containing relevant context for the requested action\n\nWhen a node receives a remote command message, it processes the command and sends a response message back to the backend. The response message can contain any relevant information about the status of the command, such as success or failure, and any associated data. Generally, nodes send their system metrics as response but it is not a strict requirement.\n\n\n\n\nFigure 1.2: sensor campaign command flow\n\n\n\n\n\n\n\nButler, H., M. Daly, A. Doyle, S. Gillies, S. Hagen, and T. Schaub. 2016. “The GeoJSON Format.” RFC 7946. RFC Editor / RFC Editor; Internet Requests for Comments.\n\n\nECMA. 2017. ECMA-404: The JSON Data Interchange Syntax. Geneva, Switzerland: ECMA (European Association for Standardizing Information and Communication Systems). https://www.ecma-international.org/publications-and-standards/standards/ecma-404/.\n\n\n“NATS.” n.d. NATS.io. https://nats.io/about."
  },
  {
    "objectID": "chapters/system-architecture.html",
    "href": "chapters/system-architecture.html",
    "title": "1 System architecture",
    "section": "",
    "text": "Several different software components are required to ensure the system can:\n\npersist general data on disk, such as node telemetry and hardware information\nreceive and store large volumes of radio signal samples organized in \nmaintain a reliable and fault-tolerant connection between the backend and an unknown number of nodes\n\nThe currently implemented software architecture is summarized in Figure 1.1.\n\n\n\n\nFigure 1.1: high-level system architecture\n\n\n\n\n\nOpenRFSense is built upon several different modern technologies, interconnected by mainstream networking protocols.\n\n\nOpenRFSense is designed to run on a variety of hardware platforms, including PCs, servers, and embedded systems. The hardware requirements depend on the specific use case and workload, but typically include a multi-core processor, sufficient memory and storage, and one or more software-defined radio (SDR) devices acting as signal receivers.\n\n\n\nOpenRFSense relies on one or more SDR devices to capture and analyze radio frequency signals. The SDR devices are connected to the hardware platform via USB or PCIe interfaces and can be controlled using open-source software libraries such as GNU Radio. The SDR device is responsible for capturing radio signals from the environment.\n\n\n\nThanks to the choice of programming language (Golang (“The Go Programming Language,” n.d.)), both the backend and node software can be compiled and deployed on most modern operating systems and hardware configurations (e.g. Windows on ARM, Linux on x86, MacOS on M1). The backend service is also developed with containerization in mind, making it possible to deploy the software securely and avoiding strict dependency on host system configuration.\n\n\n\nOpenRFSense uses a variety of signal processing and analysis techniques to extract useful information from the captured radio frequency signals. This includes techniques such as Fast Fourier Transform (Heideman, Johnson, and Burrus 1984) (FFT), digital signal processing (DSP), and machine learning algorithms. See ?@sec-signalProcessing for a more in-depth explanation of the data analysis process.\n\n\n\nOpenRFSense provides a web-based user interface for configuring, managing, and visualizing the captured data. The user interface includes features such as real-time spectrum displays, signal analysis tools, and alerting mechanisms. The system also provides APIs for integration with external tools and services.\n\n\n\n\nThe backend service is a monolithic application which combines user interface and data management code. It can be broken down into several modular components which all depend only on shared configuration in the form of a file or environment variables on the host system.\nThe internal messaging service maintains a constant communication stream between the backend and the various nodes deployed by the user. It provides a scalable and fault-tolerant solution for message delivery to the remote nodes. It is documented in ?@sec-serviceMessaging.\nAnother critical component is the web-based user interface (UI) which is the main interactive mean for the user to communicate with the other components inside the backend service. An in-depth explanation, complete with other high-level considerations, is contained in ?@sec-ui.\n\n\nTo allow external access to stored data, a REST (REpresentational State Transfer, defined in (R. T. Fielding and Taylor 2000)) API is provided by the backend. Such a system allows authorized applications to query data through a standardized interface. Currently, the following data can be fetched from the backend:\n\nsignal measurements taken by a specific node and belonging to a certain campaign\na list of all nodes currently connected to the messaging system\nnode metrics and system status for a specific node\n\nThe API can also actively request actions to be carried out by the nodes. To ensure bad actors cannot arbitrarily send command requests to the system, all requests which perform an action that can change the state of the system require a form of authentication. The currently implemented authentication method is Basic HTTP Authentication (a Web standard, see (R. Fielding and Reschke 2014)).\n\n\n\nSince radio signal data can be dense and structured as large inbound TCP packets, a storage layer capable of extremely fast writes to memory is needed. The BadgerDB (“BadgerDB,” n.d.) key-value store was chosen due to the maturity of the software and it being natively developed in Golang, providing easier integration into the existing backend code. BadgerDB is capable, in optimal conditions (sufficient RAM and a modern solid state disk), of writing several gigabytes of data per second to disk. In practical testing, BadgerDB has proven more than sufficient for handling raw inbound signal data from several nodes at a time.\n\n\n\nA support database is used to store persistent data, which is required to survive service outages or is generally better kept for an unspecified amount of time. PostgreSQL (Group 2023) was chosen mainly due to the maturity and notoriety of the project. From the project website:\n\nPostgreSQL is a powerful, open source object-relational database system that uses and extends the SQL language combined with many features that safely store and scale the most complicated data workloads.\n\nPostgreSQL is widely available and easily deployable even using container technology. A native Golang implementation of the database connection and communication protocol is used internally to store data such as past node metrics received through the messaging system, or signal measurement campaign data (start date and time, end date and time, etc.). Such data is then available for querying through the REST API documented above (in Section 1.2.1).\n\n\n\n\nThe node software is developed upon much the same technologies as the backend to ease integration between the two and reduce development overhead. Being developed to run natively on embedded devices as a self-contained application, several software components are needed to fullfil all required functions.\nThe application is available both as a standalone, statically-linked executable and a more user-friendly prebuilt system image based on the Raspbian OS. The system image comes pre-configured with required system components such as:\n\na SystemD (“Systemd,” n.d.) service which starts the node management software on boot\nthe OpenRFSense node management application\nthe external, low-level program which interfaces with the SDR hardware (orfs-sensor)\nsome useful signal decoding software, also part of the project\n\nThe following sections describe the main components of the node management software.\n\n\nA critical component for the node software is the metrics collector. This component is responsible for providing a current snapshot of the status of both hardware and software of the system, which will then be stored by the backend. The metrics message format and message exchange is documented more extensively in ?@sec-metrics.\n\n\n\nThe node software relies on an external process for data acquisition and delivery. Not being originally developed with integration in mind, such a program is managed as a zero-knowledge black box, executed as a child process by generating command-line arguments and passing them to the program.\n\n\n\n\nmeasurement process flow\n\n\n\n\n\n\nMuch like the backend, the node provides users with a web-based UI to manage system functionality. Additionally, the UI lets users configure and reboot the system without needing an external monitor or peripherals for easier system administration of embedded devices. A description of the node UI with screenshots is contained in ?@sec-nodeUi.\nThe interface is only accessible on the same network as the node, to avoid exposing administration functionality to the public internet. Additionally, for thirty minutes after the system is booted, the UI is accessible by connecting to the device through a temporary WiFi access point if the hardware is capable of creating one such connection.\n\n\n\n\n“BadgerDB.” n.d. https://dgraph.io/docs/badger.\n\n\nFielding, Roy Thomas, and Richard N. Taylor. 2000. “Architectural Styles and the Design of Network-Based Software Architectures.” University of California, Irvine.\n\n\nFielding, R., and J. Reschke. 2014. “Hypertext Transfer Protocol (HTTP/1.1): Authentication.” RFC 7235. RFC Editor / RFC Editor; Internet Requests for Comments. http://www.rfc-editor.org/rfc/rfc7235.txt.\n\n\nGroup, PostgreSQL Global Development. 2023. “PostgreSQL.” PostgreSQL. February 25, 2023. https://www.postgresql.org/.\n\n\nHeideman, M., D. Johnson, and C. Burrus. 1984. “Gauss and the History of the Fast Fourier Transform.” IEEE ASSP Magazine 1 (4): 14–21. https://doi.org/10.1109/MASSP.1984.1162257.\n\n\n“Systemd.” n.d. https://www.freedesktop.org/wiki/Software/systemd/.\n\n\n“The Go Programming Language.” n.d. https://go.dev/."
  },
  {
    "objectID": "chapters/system-architecture.html#high-level-components",
    "href": "chapters/system-architecture.html#high-level-components",
    "title": "1 System architecture",
    "section": "",
    "text": "OpenRFSense is built upon several different modern technologies, interconnected by mainstream networking protocols.\n\n\nOpenRFSense is designed to run on a variety of hardware platforms, including PCs, servers, and embedded systems. The hardware requirements depend on the specific use case and workload, but typically include a multi-core processor, sufficient memory and storage, and one or more software-defined radio (SDR) devices acting as signal receivers.\n\n\n\nOpenRFSense relies on one or more SDR devices to capture and analyze radio frequency signals. The SDR devices are connected to the hardware platform via USB or PCIe interfaces and can be controlled using open-source software libraries such as GNU Radio. The SDR device is responsible for capturing radio signals from the environment.\n\n\n\nThanks to the choice of programming language (Golang (“The Go Programming Language,” n.d.)), both the backend and node software can be compiled and deployed on most modern operating systems and hardware configurations (e.g. Windows on ARM, Linux on x86, MacOS on M1). The backend service is also developed with containerization in mind, making it possible to deploy the software securely and avoiding strict dependency on host system configuration.\n\n\n\nOpenRFSense uses a variety of signal processing and analysis techniques to extract useful information from the captured radio frequency signals. This includes techniques such as Fast Fourier Transform (Heideman, Johnson, and Burrus 1984) (FFT), digital signal processing (DSP), and machine learning algorithms. See ?@sec-signalProcessing for a more in-depth explanation of the data analysis process.\n\n\n\nOpenRFSense provides a web-based user interface for configuring, managing, and visualizing the captured data. The user interface includes features such as real-time spectrum displays, signal analysis tools, and alerting mechanisms. The system also provides APIs for integration with external tools and services."
  },
  {
    "objectID": "chapters/system-architecture.html#backend-architecture",
    "href": "chapters/system-architecture.html#backend-architecture",
    "title": "1 System architecture",
    "section": "",
    "text": "The backend service is a monolithic application which combines user interface and data management code. It can be broken down into several modular components which all depend only on shared configuration in the form of a file or environment variables on the host system.\nThe internal messaging service maintains a constant communication stream between the backend and the various nodes deployed by the user. It provides a scalable and fault-tolerant solution for message delivery to the remote nodes. It is documented in ?@sec-serviceMessaging.\nAnother critical component is the web-based user interface (UI) which is the main interactive mean for the user to communicate with the other components inside the backend service. An in-depth explanation, complete with other high-level considerations, is contained in ?@sec-ui.\n\n\nTo allow external access to stored data, a REST (REpresentational State Transfer, defined in (R. T. Fielding and Taylor 2000)) API is provided by the backend. Such a system allows authorized applications to query data through a standardized interface. Currently, the following data can be fetched from the backend:\n\nsignal measurements taken by a specific node and belonging to a certain campaign\na list of all nodes currently connected to the messaging system\nnode metrics and system status for a specific node\n\nThe API can also actively request actions to be carried out by the nodes. To ensure bad actors cannot arbitrarily send command requests to the system, all requests which perform an action that can change the state of the system require a form of authentication. The currently implemented authentication method is Basic HTTP Authentication (a Web standard, see (R. Fielding and Reschke 2014)).\n\n\n\nSince radio signal data can be dense and structured as large inbound TCP packets, a storage layer capable of extremely fast writes to memory is needed. The BadgerDB (“BadgerDB,” n.d.) key-value store was chosen due to the maturity of the software and it being natively developed in Golang, providing easier integration into the existing backend code. BadgerDB is capable, in optimal conditions (sufficient RAM and a modern solid state disk), of writing several gigabytes of data per second to disk. In practical testing, BadgerDB has proven more than sufficient for handling raw inbound signal data from several nodes at a time.\n\n\n\nA support database is used to store persistent data, which is required to survive service outages or is generally better kept for an unspecified amount of time. PostgreSQL (Group 2023) was chosen mainly due to the maturity and notoriety of the project. From the project website:\n\nPostgreSQL is a powerful, open source object-relational database system that uses and extends the SQL language combined with many features that safely store and scale the most complicated data workloads.\n\nPostgreSQL is widely available and easily deployable even using container technology. A native Golang implementation of the database connection and communication protocol is used internally to store data such as past node metrics received through the messaging system, or signal measurement campaign data (start date and time, end date and time, etc.). Such data is then available for querying through the REST API documented above (in Section 1.2.1)."
  },
  {
    "objectID": "chapters/system-architecture.html#node-architecture",
    "href": "chapters/system-architecture.html#node-architecture",
    "title": "1 System architecture",
    "section": "",
    "text": "The node software is developed upon much the same technologies as the backend to ease integration between the two and reduce development overhead. Being developed to run natively on embedded devices as a self-contained application, several software components are needed to fullfil all required functions.\nThe application is available both as a standalone, statically-linked executable and a more user-friendly prebuilt system image based on the Raspbian OS. The system image comes pre-configured with required system components such as:\n\na SystemD (“Systemd,” n.d.) service which starts the node management software on boot\nthe OpenRFSense node management application\nthe external, low-level program which interfaces with the SDR hardware (orfs-sensor)\nsome useful signal decoding software, also part of the project\n\nThe following sections describe the main components of the node management software.\n\n\nA critical component for the node software is the metrics collector. This component is responsible for providing a current snapshot of the status of both hardware and software of the system, which will then be stored by the backend. The metrics message format and message exchange is documented more extensively in ?@sec-metrics.\n\n\n\nThe node software relies on an external process for data acquisition and delivery. Not being originally developed with integration in mind, such a program is managed as a zero-knowledge black box, executed as a child process by generating command-line arguments and passing them to the program.\n\n\n\n\nmeasurement process flow\n\n\n\n\n\n\nMuch like the backend, the node provides users with a web-based UI to manage system functionality. Additionally, the UI lets users configure and reboot the system without needing an external monitor or peripherals for easier system administration of embedded devices. A description of the node UI with screenshots is contained in ?@sec-nodeUi.\nThe interface is only accessible on the same network as the node, to avoid exposing administration functionality to the public internet. Additionally, for thirty minutes after the system is booted, the UI is accessible by connecting to the device through a temporary WiFi access point if the hardware is capable of creating one such connection.\n\n\n\n\n“BadgerDB.” n.d. https://dgraph.io/docs/badger.\n\n\nFielding, Roy Thomas, and Richard N. Taylor. 2000. “Architectural Styles and the Design of Network-Based Software Architectures.” University of California, Irvine.\n\n\nFielding, R., and J. Reschke. 2014. “Hypertext Transfer Protocol (HTTP/1.1): Authentication.” RFC 7235. RFC Editor / RFC Editor; Internet Requests for Comments. http://www.rfc-editor.org/rfc/rfc7235.txt.\n\n\nGroup, PostgreSQL Global Development. 2023. “PostgreSQL.” PostgreSQL. February 25, 2023. https://www.postgresql.org/.\n\n\nHeideman, M., D. Johnson, and C. Burrus. 1984. “Gauss and the History of the Fast Fourier Transform.” IEEE ASSP Magazine 1 (4): 14–21. https://doi.org/10.1109/MASSP.1984.1162257.\n\n\n“Systemd.” n.d. https://www.freedesktop.org/wiki/Software/systemd/.\n\n\n“The Go Programming Language.” n.d. https://go.dev/."
  },
  {
    "objectID": "chapters/user-interface.html",
    "href": "chapters/user-interface.html",
    "title": "1 User interface",
    "section": "",
    "text": "The user interface plays an essential role in enabling users to interact with the system effectively. A well-designed user interface can make it easy for users to navigate between pages and perform several complex tasks related to node system and data management.\nThe UI is served to the user as a collection of web pages by the backend service. The pages are generated on demand with up-to-date information and take advantage of modern web technologies.\n\n\nSeveral design principles guided the development of the user interface, mainly:\n\nConsistency: Elements such as fonts, colors, and icons are consistent throughout the interface, making it easier for users to navigate between UI sections and use the system.\nSimplicity: The user interface is simple and easy to use. The simplicity principle ensures that the interface is not cluttered with unnecessary elements, making it easy for users to find what they need.\nFeedback: The user interface provides users with immediate feedback to let them know that their actions have been registered. This principle ensures that users are not left wondering whether their actions have been successful.\nAccessibility: The user interface is designed to be accessible to all users, including those with disabilities. This principle ensures that users with different abilities can use the system without encountering any usability barriers.\n\n\n\n\n\nThe UI is aimed at users with a certain technical background and previous knowledge of the system, but it is designed to be easily navigated through by any given user.\n\n\n\n\nUI hyperlink structure\n\n\n\n\n\nThe dashboard acts as the homepage of the UI. It is the first page served by the backend on the root address and is the first interactive element the user will be shown on connection to the system.\n\n\n\nDashboard\n\n\nThe first element presented by the UI is a table containing useful information about all nodes connected to the backend, such as node location and unique identifier. Each node can be selected with a checkbox to take part in a measurement campaign (configurable through a pop-up modal dialog). Every row also contains a link to a page which visualizes a node’s metrics and location in more detail (see Section 1.2.2).\nThe homepage of the UI provides a map of the world, with the locations of all the sensors in the OpenRFSense network indicated by markers. Clicking on the markers yields basic information about each node, such as its ID and the last time it was active, and a link the node-specific overview page.\n\n\n\nA node-specific overview page is also generated for each node connected to the backend and the messaging system. This page generally contains all required node metrics returned by a request to the node, as well as more detailed node system information if available (see ?@sec-metrics). The node overview page also contains a map but only showing a single marker corresponding to the node being queried and centered on the node’s location, if provided.\n\n\n\nNode overview page\n\n\nA table containing a list of all past and ongoing measurement campaigns is also provided to the user, with management controls on each row to download the signal data in various formats or delete it from the storage. The controls are non-interactive if the campaign is still ongoing.\n\n\n\n\nTo make the REST API (defined in ?@sec-restApi) easily accessible to users and external applications, a documentation page is automatically generated using Swagger (OpenAPI specification version 2.0 (“OpenAPI Specification - Version 2.0 | Swagger,” n.d.)). The generated page contains all the necessary documentation to query data and send commands to the backend, complete with examples and request and response formats in textual JSON.\n\n\n\nAPI documentation\n\n\n\n\n\n\nEach node’s local management UI provides a high-level management over the host system running the node. As such, it must present important information in logical order, starting with connection status (both WiFi and physical). On remote devices, this facilitates troubleshooting and provides an alternative method of restoring connection to a node.\n\n\n\nNode system management page\n\n\nA simple text editor is also provided for the node management software configuration. Each change followed by a click on the “Save” button will write the changes to the configuration file and reboot the system.\n\n\n\n\n\n“OpenAPI Specification - Version 2.0 | Swagger.” n.d. https://swagger.io/specification/v2/."
  },
  {
    "objectID": "chapters/user-interface.html#design-principles",
    "href": "chapters/user-interface.html#design-principles",
    "title": "1 User interface",
    "section": "",
    "text": "Several design principles guided the development of the user interface, mainly:\n\nConsistency: Elements such as fonts, colors, and icons are consistent throughout the interface, making it easier for users to navigate between UI sections and use the system.\nSimplicity: The user interface is simple and easy to use. The simplicity principle ensures that the interface is not cluttered with unnecessary elements, making it easy for users to find what they need.\nFeedback: The user interface provides users with immediate feedback to let them know that their actions have been registered. This principle ensures that users are not left wondering whether their actions have been successful.\nAccessibility: The user interface is designed to be accessible to all users, including those with disabilities. This principle ensures that users with different abilities can use the system without encountering any usability barriers."
  },
  {
    "objectID": "chapters/user-interface.html#interface-components-and-structure",
    "href": "chapters/user-interface.html#interface-components-and-structure",
    "title": "1 User interface",
    "section": "",
    "text": "The UI is aimed at users with a certain technical background and previous knowledge of the system, but it is designed to be easily navigated through by any given user.\n\n\n\n\nUI hyperlink structure\n\n\n\n\n\nThe dashboard acts as the homepage of the UI. It is the first page served by the backend on the root address and is the first interactive element the user will be shown on connection to the system.\n\n\n\nDashboard\n\n\nThe first element presented by the UI is a table containing useful information about all nodes connected to the backend, such as node location and unique identifier. Each node can be selected with a checkbox to take part in a measurement campaign (configurable through a pop-up modal dialog). Every row also contains a link to a page which visualizes a node’s metrics and location in more detail (see Section 1.2.2).\nThe homepage of the UI provides a map of the world, with the locations of all the sensors in the OpenRFSense network indicated by markers. Clicking on the markers yields basic information about each node, such as its ID and the last time it was active, and a link the node-specific overview page.\n\n\n\nA node-specific overview page is also generated for each node connected to the backend and the messaging system. This page generally contains all required node metrics returned by a request to the node, as well as more detailed node system information if available (see ?@sec-metrics). The node overview page also contains a map but only showing a single marker corresponding to the node being queried and centered on the node’s location, if provided.\n\n\n\nNode overview page\n\n\nA table containing a list of all past and ongoing measurement campaigns is also provided to the user, with management controls on each row to download the signal data in various formats or delete it from the storage. The controls are non-interactive if the campaign is still ongoing.\n\n\n\n\nTo make the REST API (defined in ?@sec-restApi) easily accessible to users and external applications, a documentation page is automatically generated using Swagger (OpenAPI specification version 2.0 (“OpenAPI Specification - Version 2.0 | Swagger,” n.d.)). The generated page contains all the necessary documentation to query data and send commands to the backend, complete with examples and request and response formats in textual JSON.\n\n\n\nAPI documentation\n\n\n\n\n\n\nEach node’s local management UI provides a high-level management over the host system running the node. As such, it must present important information in logical order, starting with connection status (both WiFi and physical). On remote devices, this facilitates troubleshooting and provides an alternative method of restoring connection to a node.\n\n\n\nNode system management page\n\n\nA simple text editor is also provided for the node management software configuration. Each change followed by a click on the “Save” button will write the changes to the configuration file and reboot the system.\n\n\n\n\n\n“OpenAPI Specification - Version 2.0 | Swagger.” n.d. https://swagger.io/specification/v2/."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Abstract",
    "section": "",
    "text": "Abstract\nThis thesis focuses on the design and implementation of a software-defined radio (SDR) platform for spectrum monitoring and analysis. The objective of the project is to provide a low-cost and scalable solution for real-time spectrum analysis and visualization. The project is based on open source technology and is aimed at being accessible and usable by individuals, businesses, and organizations which may need to monitor and understand the usage of the radio spectrum in remote locations.\nThis thesis consists of three logical macro-sections. The first section of the thesis provides an overview of software-defined radio technology and its role in modern radio communication systems. This includes a discussion of the hardware and software components used in SDR systems, as well as the algorithms and techniques employed to perform real-time spectrum analysis and visualization.\nThe second part of the thesis focuses on the design and implementation of the open source project , which was created and maintained by the author of this thesis. This section focuses mainly on the engineering of the various software components which comprise the project and the way such components are integrated.\nFinally, the thesis evaluates the performance and accuracy of the SDR platform and its ability to provide a low-cost and scalable solution for spectrum monitoring and analysis. The conclusion provides recommendations for future work, including ways to further improve the accuracy and performance of the platform, as well as potential applications for similar SDR-powered software in various fields, such as wireless networking and radio communication systems.\nOverall, this thesis aims to provide a comprehensive analysis of the design and implementation of an SDR platform for spectrum monitoring and analysis, as well as a useful example of an accessible, open source software suite."
  }
]